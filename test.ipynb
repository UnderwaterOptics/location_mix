{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import linalg as LA\n",
    "ones = torch.ones((64,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13.8564)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(ones, 2, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lichen/.conda/envs/py310/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/lichen/code/UW/auv_location_pl-master/data/geometry.py\u001b[0m(72)\u001b[0;36mcord2rad\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     70 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     71 \u001b[0;31m        \u001b[0;31m# 弧度，如果要算角度，使用np.degrees()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 72 \u001b[0;31m        \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mangle_between\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     73 \u001b[0;31m        \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mDA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mangle_between\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     74 \u001b[0;31m        \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mangle_between\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from data.loc_data import LocData\n",
    "r = 0.8\n",
    "max_deg = 30\n",
    "max_x = 30\n",
    "min_x = r\n",
    "data_len = 100\n",
    "\n",
    "loc_data = LocData(r, max_deg, max_x, data_len)\n",
    "\n",
    "loc_data_sample = loc_data._sample_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.tensor([1,2,3], dtype=torch.float).unsqueeze(0).repeat((4, 1))\n",
    "b = torch.tensor([4,5,6], dtype=torch.float).unsqueeze(0).repeat((4, 1))\n",
    "# c = torch.dot(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005499340079190495"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.0231-0.0181)/(0.9273-0.0181)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "d= torch.mul(a, b)\n",
    "e = torch.norm(a, 2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = torch.einsum('ij, ij -> i', [a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.5524, 8.5524, 8.5524, 8.5524])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f/e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.29577951308232"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "180/np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.729577951308232"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.1 *180/np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5233333333333333"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "30 * 3.14 /180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  831, 100.000% Params, 894.0 Mac, 100.000% MACs, \n",
      "  (model): Sequential(\n",
      "    831, 100.000% Params, 894.0 Mac, 100.000% MACs, \n",
      "    (0): Flatten(0, 0.000% Params, 0.0 Mac, 0.000% MACs, start_dim=1, end_dim=-1)\n",
      "    (1): Linear(24, 2.888% Params, 24.0 Mac, 2.685% MACs, in_features=3, out_features=6, bias=True)\n",
      "    (2): ReLU(0, 0.000% Params, 6.0 Mac, 0.671% MACs, )\n",
      "    (3): Linear(84, 10.108% Params, 84.0 Mac, 9.396% MACs, in_features=6, out_features=12, bias=True)\n",
      "    (4): ReLU(0, 0.000% Params, 12.0 Mac, 1.342% MACs, )\n",
      "    (5): Linear(312, 37.545% Params, 312.0 Mac, 34.899% MACs, in_features=12, out_features=24, bias=True)\n",
      "    (6): ReLU(0, 0.000% Params, 24.0 Mac, 2.685% MACs, )\n",
      "    (7): Linear(300, 36.101% Params, 300.0 Mac, 33.557% MACs, in_features=24, out_features=12, bias=True)\n",
      "    (8): ReLU(0, 0.000% Params, 12.0 Mac, 1.342% MACs, )\n",
      "    (9): Linear(78, 9.386% Params, 78.0 Mac, 8.725% MACs, in_features=12, out_features=6, bias=True)\n",
      "    (10): ReLU(0, 0.000% Params, 6.0 Mac, 0.671% MACs, )\n",
      "    (11): Linear(21, 2.527% Params, 21.0 Mac, 2.349% MACs, in_features=6, out_features=3, bias=True)\n",
      "    (12): ReLU(0, 0.000% Params, 3.0 Mac, 0.336% MACs, )\n",
      "    (13): Linear(12, 1.444% Params, 12.0 Mac, 1.342% MACs, in_features=3, out_features=3, bias=True)\n",
      "    (14): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from ptflops import get_model_complexity_info\n",
    "from models.layers import MLP \n",
    "input_size = 3\n",
    "hidden_units = [6, 12, 24, 12, 6, 3]\n",
    "mlp = MLP(input_size, hidden_units)\n",
    "\n",
    "flops, params = get_model_complexity_info(mlp, (1, 3), as_strings=True, print_per_layer_stat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'894.0 Mac'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'831'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7432640250097023\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "d = 1\n",
    "r = 0.8\n",
    "\n",
    "OA = np.sqrt(3)*r/3.\n",
    "DA = np.sqrt(d**2 + OA**2)\n",
    "\n",
    "# 夹角计算\n",
    "alpha = np.arccos((DA**2 + DA**2 - r**2)/(2*DA*DA))\n",
    "print(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.778292884982778$"
      ],
      "text/plain": [
       "-0.778292884982778"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sympy as sp\n",
    "x= sp.symbols('x')\n",
    "# 距离计算\n",
    "def f(x):\n",
    "    a = r**2 / 4\n",
    "    b = r**2 / 3\n",
    "    y = sp.sqrt(a/(sp.sin(x/2)**2)-b)\n",
    "    # y = sp.sqrt(r**2/4./(sp.sin(x/2)**2) - ((r, 3)/3)**2)\n",
    "    return y\n",
    "# 求导\n",
    "fprime = sp.diff(f(x),x)\n",
    "\n",
    "deltaF = fprime.evalf(subs={x:alpha})\n",
    "\n",
    "deltaF*0.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0471975511965976"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.radians(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0471975511965976"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "60 / 180 * np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28867513459481287"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(3) /6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1370029134485002"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0188 * 190/np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from models.mas import MultiHeadAttention\n",
    "from models.max import VasNet\n",
    "\n",
    "# 创建一个多头注意力层，输入维度为3，输出维度为3，头数为1\n",
    "mha = MultiHeadAttention(input_dim=3,output_dim=3,num_heads=3)\n",
    "# 创建一个随机输入，批量大小为4，序列长度为5，输入维度为3\n",
    "x = torch.randn(4 ,6 ,3)\n",
    "# 前向传播，得到输出\n",
    "y = mha(x)\n",
    "# 输出形状为[4 ,5 ,3]，即[批量大小，序列长度，输出维度]\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "vas = VasNet(3, 3, 4, 12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from models.layers import Attention_seq\n",
    "\n",
    "att = Attention_seq(query_dim = 3, heads = 100, dim_head = 10)\n",
    "x = torch.randn(4 ,6 ,3)\n",
    "# 前向传播，得到输出\n",
    "y = att(x)\n",
    "print(y[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.mas import AttEncoder\n",
    "import torch\n",
    "\n",
    "dim_list = []\n",
    "# dim_in_feats = 1\n",
    "# dim_ff = 6\n",
    "# dim_out_feats = 1\n",
    "# heads = 3\n",
    "# dim_head = 12\n",
    "dim_list.append({'dim_in': 1, \n",
    "                 'dim_ff': 6,\n",
    "                 'dim_out': 6,\n",
    "                 'head': 3,\n",
    "                 'dim_head': 12,\n",
    "                 }\n",
    "                 )\n",
    "dim_list.append({'dim_in': 6, \n",
    "                 'dim_ff': 12,\n",
    "                 'dim_out': 12,\n",
    "                 'head': 3,\n",
    "                 'dim_head': 12,\n",
    "                 }\n",
    "                 )\n",
    "# dim_list.append({'dim_in': 12, \n",
    "#                  'dim_ff': 6,\n",
    "#                  'dim_out': 24,\n",
    "#                  'head': 3,\n",
    "#                  'dim_head': 12,\n",
    "#                  }\n",
    "#                  )\n",
    "\n",
    "net = AttEncoder(dim_list)\n",
    "x = torch.randn(4, 3, 1)\n",
    "# net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (6) must match the size of tensor b (12) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y \u001b[39m=\u001b[39m net(x)\n",
      "File \u001b[0;32m~/.conda/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/code/UW/auv_location_pl-master/models/mas.py:66\u001b[0m, in \u001b[0;36mAttEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     65\u001b[0m     \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 66\u001b[0m         x \u001b[39m=\u001b[39m layer(x)\n\u001b[1;32m     67\u001b[0m         \u001b[39m# print(x.shape)\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.conda/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/code/UW/auv_location_pl-master/models/mas.py:123\u001b[0m, in \u001b[0;36mAttLayer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39m# pdb.set_trace()\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \n\u001b[1;32m    121\u001b[0m \u001b[39m# import score\u001b[39;00m\n\u001b[1;32m    122\u001b[0m ff_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeed_forward(y)\n\u001b[0;32m--> 123\u001b[0m y \u001b[39m=\u001b[39m y\u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdrop_out2(ff_output)\n\u001b[1;32m    124\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm2(y)\n\u001b[1;32m    126\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (6) must match the size of tensor b (12) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "y = net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.4201e-05],\n",
       "         [-1.2198e-08],\n",
       "         [ 2.9017e-06]],\n",
       "\n",
       "        [[-7.5287e-07],\n",
       "         [-1.3637e-06],\n",
       "         [ 5.4372e-07]],\n",
       "\n",
       "        [[-7.0595e-06],\n",
       "         [-4.3592e-06],\n",
       "         [ 4.8147e-06]],\n",
       "\n",
       "        [[-3.6498e-06],\n",
       "         [ 1.2080e-06],\n",
       "         [-8.6904e-07]]], grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,10,1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch\n",
    "\n",
    "pe = nn.Parameter(torch.eye(3), requires_grad=False)\n",
    "# x = nn.Parameter(torch.tensor(1, 0, 0), requires_grad=False)\n",
    "# y = nn.Parameter(torch.tensor(0, 1, 0), requires_grad=False)\n",
    "# z = nn.Parameter(torch.tensor(0, 0, 1), requires_grad=False)\n",
    "x =  torch.randn(8,3,1)\n",
    "# pe = torch.stack((x, y, z), dim = 1)\n",
    "y =  torch.cat([x, pe.expand((8,3,3))], dim = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "b, l, d = x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    z_list = []\n",
    "    r_list = []\n",
    "\n",
    "    N = 1000000\n",
    "\n",
    "    f = open(\"../shared/dataset.txt\", \"w\")\n",
    "    rr = np.random.uniform(0, 30000, N)\n",
    "    fai = np.random.uniform(0, np.pi, N)\n",
    "    theta = np.random.uniform(0, np.pi * 2, N)\n",
    "    cnt = 0\n",
    "\n",
    "    xx = rr * np.sin(theta) * np.cos(fai)\n",
    "    yy = rr * np.sin(theta) * np.cos(fai)\n",
    "    zz = rr * np.cos(theta)\n",
    "\n",
    "    for i in range(N):\n",
    "        x = xx[i]\n",
    "        y = yy[i]\n",
    "        z = zz[i]\n",
    "        r = np.sqrt(x * x + y * y + z * z)\n",
    "\n",
    "        if z > 0:\n",
    "            continue\n",
    "        if r > 30000:\n",
    "            continue\n",
    "        cnt += 1\n",
    "\n",
    "        p1 = np.array([[400], [0], [0]])\n",
    "        p2 = np.array([[-400], [0], [0]])\n",
    "        p3 = np.array([[0], [400 * np.sqrt(3)], [0]])\n",
    "\n",
    "        T = np.array([[x], [y], [z]])\n",
    "\n",
    "        op1 = p1 + T\n",
    "        op2 = p2 + T\n",
    "        op3 = p3 + T\n",
    "\n",
    "        e1 = op1 / np.linalg.norm(op1)\n",
    "        e2 = op2 / np.linalg.norm(op2)\n",
    "        e3 = op3 / np.linalg.norm(op3)\n",
    "\n",
    "        print(\"[{}] [INPUT]e1=({:.6f},{:.6f},{:.6f}) e2=({:.6f},{:.6f},{:.6f}) e3=({:.6f},{:.6f},{:.6f}) \"\n",
    "              \"[OUTPUT](tx,ty,tz)=({:.6f},{:.6f},{:.6f})\".format(i, e1[0][0], e1[1][0], e1[2][0], e2[0][0], e2[1][0], e2[2][0], e3[0][0], e3[1][0], e3[2][0], x, y, z))\n",
    "\n",
    "        f.write(\"{}\\n\".format(cnt))\n",
    "        f.write(\"{:.6f} {:.6f} {:.6f}\\n\".format(e1[0][0], e1[1][0], e1[2][0]))\n",
    "        f.write(\"{:.6f} {:.6f} {:.6f}\\n\".format(e2[0][0], e2[1][0], e2[2][0]))\n",
    "        f.write(\"{:.6f} {:.6f} {:.6f}\\n\".format(e3[0][0], e3[1][0], e3[2][0]))\n",
    "        f.write(\"{:.6f} {:.6f} {:.6f}\\n\".format(x, y, z))\n",
    "\n",
    "        x_list.append(x)\n",
    "        y_list.append(y)\n",
    "        z_list.append(z)\n",
    "        r_list.append(r)\n",
    "\n",
    "    f.write(\"-1\\n\")\n",
    "    f.close()\n",
    "\n",
    "    # plt.suptitle(\"Distribution\")\n",
    "    # plt.subplot(2, 2, 1)\n",
    "    # plt.title(\"x\")\n",
    "    # plt.hist(np.array(x_list), 1000)\n",
    "    # plt.subplot(2, 2, 2)\n",
    "    # plt.title(\"y\")\n",
    "    # plt.hist(np.array(y_list), 1000)\n",
    "    # plt.subplot(2, 2, 3)\n",
    "    # plt.title(\"z\")\n",
    "    # plt.hist(np.array(z_list), 1000)\n",
    "    # plt.subplot(2, 2, 4)\n",
    "    # plt.title(\"r\")\n",
    "    # plt.hist(np.array(r_list), 1000)\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([26695.65807722,  9356.07993572, 23698.96333304, 16039.19777351,\n",
       "        1863.74496058, 17120.84681396, 10062.88615396, 16007.77064822,\n",
       "       23790.35683125, 10053.70416612])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vector3D(35.2644)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from data.geometry import Vector3D\n",
    "\n",
    "T = Vector3D([1, 1, 1])\n",
    "t = T.vertical_angle\n",
    "\n",
    "t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vector3D(45.)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lichen/.conda/envs/py310/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from data.loc_data import LocData\n",
    "import numpy as np\n",
    "r = 0.8\n",
    "max_deg = 30\n",
    "max_x = 25\n",
    "max_rad = np.radians(max_deg, dtype=np.float32)\n",
    "max_d = np.sqrt(max_x * max_x + 2 * (max_x * np.tan(max_rad)) ** 2)\n",
    "\n",
    "data_len = 100\n",
    "\n",
    "ldata = LocData(r, max_deg, max_d, max_x, None, data_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1, b1, c1, T, t, d, d_max = ldata._sample_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vector3D([ 0.9195, -0.3925, -0.0190])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'A1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m A1\n",
      "\u001b[0;31mNameError\u001b[0m: name 'A1' is not defined"
     ]
    }
   ],
   "source": [
    "A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vector3D([125345.0312, -53508.6641,  -2590.0686])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 * d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vector3D([125192.3828, -53443.5039,  -7205.7168])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vector3D([ 0.9184, -0.3921, -0.0529])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vector3D([125192.3828, -53443.5039,  -7205.7168])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t*d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vector3D(136313.1094)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'A1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m A1\u001b[39m-\u001b[39mT\n",
      "\u001b[0;31mNameError\u001b[0m: name 'A1' is not defined"
     ]
    }
   ],
   "source": [
    "A1-T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vector3D([    0.0000, -4000.0000, -2309.4014])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B1-T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vector3D([    0.0000,  4000.0000, -2309.4014])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C1-T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vector3D([   0.0000,    0.0000, 4618.8022])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldata.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff157c5de1838f97bdd1abf08a086febf8e5e86d094d4eaa1859dc44e200d8da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
